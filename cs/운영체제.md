# 운영체제



### 운영 체제

- 운영 체제는 컴퓨터 하드웨어가 컴퓨터 소프트웨어와 통신하고 작동하도록하는 소프트웨어 프로그램



### CPU/GPU

- CPU
  - CPU는 입출력장치, 기억장치, 연산장치 등을 포함한 컴퓨터 리소스를 관리하는 최상위 계층의 중앙처리장치
  - 데이터 처리와 더불어 프로그램에서 작업의 우선순위를 지정하고 전환하며 가상 메모리를 관리하는 등의 역할을 한다. 
  - CPU는 직렬 처리에 최적화된 몇 개의 코어로 구성되어 있다.
- GPU
  - GPU는 반복적이고 비슷한 대량의 연산을 수행하며 이를 병렬적(parallel)으로 나누어 작업하기 때문에 CPU에 비해 속도가 압도적으로 빠르다. 
  - GPU는 병렬 처리용으로 설계된 수 천 개의 보다 소형이고 효율적인 코어로 구성되어 있다.



### Byte Ordering

- Byte Ordering이란 데이터가 저장되는 순서를 의미한다. Byte Ordering의 방식에는 빅엔디안(Big Endian)과 리틀엔디안(Little Endian)이 있다.
- ![img](https://blog.kakaocdn.net/dn/d61BQv/btqKGke14cT/XuxbH4w5qfkvybCbQVmiFK/img.png)



- Little Endian
  - MSB가 가장 높은 주소에 위치하는 방식
  - 마이크로프로세서에서 주로 사용된다.
  - 가장 낮은 주소에 부호값이 아닌 데이터가 먼저 오기 때문에, 바로 연산을 할 수 있다.
- Big Endian
  - MSB가 가장 낮은 주소에 위치하는 저장 방식
  - 네트워크에서 데이터를 전송할 때 주로 사용됨
  - 가장 낮은 주소에 MSB가 저장되므로, offset=0인 Byte를 보면 양수/음수를 바로 파악할 수 있다.



### 메모리

![img](https://blog.kakaocdn.net/dn/nyV7n/btqITvcHjTA/dk2V9ejhCT1P5Zngumuag1/img.png)

- 메모리는 컴퓨터에서 작업을 수행하기 위해 명령어 및 데이터가 적재되는 공간
- 프로그램을 실행하기 위한 정보들은 메모리에 저장되어 처리된다.
- 메모리는 크게 코드, 데이터, 스택, 힙 영역으로 나누어져 있다. 
  - 코드 영역은 실행될 프로그램의 코드가 저장되어 있는 영역이다. 
  - 데이터 영역은 전역 변수와 정적 변수가 저장되어 있는 영역이다. 
  - 스택 영역은 지역변수와 매개 변수가 저장되어 있으며, 함수의 호출과 함께 할당되는 영역이다. 
  - 힙 영역은 사용자에 의해 동적으로 할당되고 해제될 수 있는 메모리 영역이다. 스택 영역은 컴파일 타임에 크기가 결정되고, 힙 영역은 런 타임에 크기가 결정된다.



### 프로세스와 쓰레드

![img](https://blog.kakaocdn.net/dn/bpie8u/btqKEyScItU/ISOD7DfzGuBuPdWEfGnZxk/img.jpg)

- 프로세스
  - 정의: 메모리에 올리와 실행되고 있는 프로그램의 인스턴스
  - 특징
    - 운영체제로부터 독립된 메모리 영역을 할당받는다. (다른 프로세스의 자원에 접근 X)
      - Code, Data, Stack, Heap
    - 프로세스들은 독립적이기 때문에 통신하기 위해 IPC를 사용해야 한다(ex. 파이프, 파일, 소켓 등을 이용한 통신 방법 이용)
    - 프로세스는 최소 1개의 쓰레드(메인 쓰레드)를 가지고 있다.
-  쓰레드
  - 정의: 프로세스 내에서 할당받은 자원을 이용해 동작하는 실행 단위
  - 특징
    - 쓰레드는 프로세스 내에서 Stack만 따로 할당 받고, Code, Data, Heap 영역은 공유한다.
      (Stack을 분리한 이유는 Stack에는 함수의 호출 정보가 저장되는데, Stack을 공유하면 LIFO 구조에 의해 실행 순서가 복잡해지기 때문에 실행 흐름을 원활하게 만들기 위함이다.)
    - 쓰레드는 프로세스의 자원을 공유하기 때문에 다른 쓰레드에 의한 결과를 즉시 확인할 수 있다.
    - 프로세스 내에 존재하며 프로세스가 할당받은 자원을 이용하여 실행된다.



### User Level Thread와 Kernel Level Thread

- 구분
  - 커널 레벨 쓰레드와 유저 레벨 쓰레드는 생성 주체가 누구냐에 따라 구분된다.
  - 쓰레드를 생성하고 스케줄링하는 주체가 커널이면 커널 레벨(Kernel Level) 쓰레드라고 한다.
  - 커널에 의존적이지 않은 형태로 쓰레드의 기능을 제공하는 라이브러리를 활용할 수 있는데 이러한 방식으로 제공되는 쓰레드가 유저 레벨(User Level) 쓰레드이다.
- 장/단점
  - 커널 레벨 쓰레드의 장점은 커널이 직접 제공해 주기 때문에 안정성과 다양한 기능이 제공된다.
  - 커널 레벨 쓰레드의 단점은 유저 모드에서 커널 모드로의 전환이 빈번하게 이뤄져 성능 저하가 발생한다.
  - 유저 레벨 쓰레드의 장점은 커널은 쓰레드의 존재조차 모르기 때문에 모드 간의 전환이 없고 성능 이득이 발생한다.
  - 유저 레벨 쓰레드의 단점은 하나의 스레드가 커널에 의해 블로킹 되면 프로세스 전체가 블로킹되고, 이를 해결하려면 프로그래밍이 어려워지고 커널 레벨 쓰레드에 비해 결과 예측이 어려워진다.



### 컨텍스트 스위칭(Context Switching)

![img](https://blog.kakaocdn.net/dn/6fjl1/btqKC9ZqMz9/2I1k55j4tMdvnXZD2KyYk1/img.png)

- Context는 CPU가 해당 프로세스를 실행하기 위한 해당 프로세스의 정보들이다. 이 context는 프로세스의 PCB(Process Control Block)에 저장된다.
- Context Switching이란 인터럽트를 발생시켜 CPU에서 실행중인 프로세스를 중단하고, 다른 프로세스를 처리하기 위한 과정
- Context Switching는 현재 실행중인 프로세스의 상태(Context)를 먼저 저장하고, 다음 프로세스를 동작시켜 작업을 처리한 후에 이전에 저장된 프로세스의 상태를 다시 복구한다.
- 인터럽트란 CPU가 프로세스를 실행하고 있을 때, 입출력 하드웨어 등의 장치나 예외상황이 발생하여 처리가 필요함을 CPU에게 알리는 것을 말합니다.



### 멀티 프로세스 VS 멀티 쓰레드

- 멀티 프로세스
  - 하나의 프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 1개의 작업을 처리하도록 하는 것
  - 특징
    - 1개의 프로세스가 죽어도 자식 프로세스 이외의 다른 프로세스들은 계속 실행된다.
    - Context Switching을 위한 오버헤드(캐시 초기화, 인터럽트 등)가 발생한다.
    - 프로세스는 각각 독립적인 메모리를 할당받았기 때문에 통신하는 것이 어렵다.
- 멀티 쓰레드
  - 하나의 프로그램을 여러 개의 쓰레드로 구성하여 각 쓰레드가 1개의 작업을 처리하도록 하는 것
  - 특징
    - 프로세스를 위해 자원을 할당하는 시스템콜이나 Context Switching의 오버헤드를 줄일 수 있다.
    - 쓰레드는 메모리를 공유하기 때문에, 통신이 쉽고 자원을 효율적으로 사용할 수 있다.
    - 하나의 쓰레드에 문제가 생기면 전체 프로세스가 영향을 받는다.
    - 여러 쓰레드가 하나의 자원에 동시에 접근하는 경우 자원 공유(동기화)의 문제가 발생할 수 있다.

 

### 데드락(DeadLock)

- 프로세스가 자원을 얻기 위해 영구적으로 기다리는 상태

- 교착 상태는 한정된 자원을 여러 프로세스가 사용하고자 할 때 발생하는 상황으로, 예를 들어 다음과 같은 상황에서 데드락이 발생할 수 있다.
  - 자원 A를 가진 프로세스 P1과 자원 B를 가진 프로세스 P2가 있을 때, P1은 B를 필요로 하고 P2는 A를 필요로 한다면 두 프로세스 P1, P2는 서로 자원을 얻기위해 무한정 기다리게 된다.
- 발생 조건 - 아래 상황이 조건이기 때문에 이중 한개라도 발생하지 않도록 하면 데드락 예방이 가능하다.
  - Mutual Exclusion(뮤텍스 - 자원에 대한 동시접근 불가)
    - 한번에 여러 프로세스(혹은 쓰레드)가 한 자원에 접근하지 못하도록 막음.
  - Hold and Wait(점유하고 기다리기)
    - 자원을 가지고 있는 상태에서 다른 프로세스가 쓰는 자원(변수 같은 것)을 반납하길 기다리는 상태다
  - No Preemption(자원 뺏어오지 못함)
    - 다른 프로세스가 이미 점유한 자원을 강제로 뺏어오지 못함
  - Circular Wait(순환 형태로 대기함)
    - 각 프로세스가 순환적으로 다음 프로세스가 요구하는 자원을 가지고 있는 상태



### Daemon Thread 

- 동일한 프로세스 안에서 다른 스레드의 수행을 돕는 스레드로 다른 스레드를 서비스 해주면서 다른 스레드가 모두 종료되면 자신도 종료되는 스레드
- 프로그램이 종료되는 것을 막지 않으며 가비지 컬렉터나 메인 스레드가 데몬 스레드



### 임계 영역(critical section)

- 공유 자원을 사용하는 코드영역을 임계영역이라 한다

- 이 부분에서는 공유 자원을 동시에 수정할 수 없도록 상호 배타적으로 실행될 수 있도록 작성되어야  한다.

 

### 멀티 쓰레드 프로그래밍 작성 시 유의점

멀티 쓰레드 프로그램을 개발한다면, 다수의 쓰레드가 공유 데이터에 동시에 접근하는 경우에 상호배제 또는 동기화 기법을 통해 동시성 문제 또는 교착 상태가 발생하지 않도록 주의해야 합니다.

 

### 세마포어(Semaphore) vs 뮤텍스(Mutex) 차이

- 뮤텍스(Mutex)
  - 공유된 자원의 데이터를 여러 쓰레드가 접근하는 것을 막는 것
  - Locking 메커니즘으로 오직 하나의 쓰레드만이 동일한 시점에 뮤텍스를 얻어 임계 영역(Critical Section)에 들어올 수 있다.
  - Locking 메커니즘으로 락을 걸은 쓰레드만이 임계 영역을 나갈때 락을 해제할 수 있다.

- 세마포어(Semaphore) 
  - 공유된 자원의 데이터를 여러 프로세스가 접근하는 것을 막는 것
  - 세마포어는 Signaling 메커니즘으로 락을 걸지 않은 쓰레드도 signal을 사용해 락을 해제할 수 있다. 세마포어의 카운트를 1로 설정하면 뮤텍스처럼 활용할 수 있다.
  - 세마포어는 동기화를 위해 wait와 signal이라는 2개의 atomic operations를 사용한다.
    wait를 호출하면 세마포어의 카운트를 1줄이고, 세마포어의 카운트가 0보다 작거나 같아질 경우에 락이 실행
  - 세마포어의 카운트가 0보다 작거나 같아져 동기화가 실행된 상황에, 다른 쓰레드가 signal 함수를 호출하면 세마포어의 카운트가 1증가하고, 해당 쓰레드는 락에서 나올 수 있다.
  - 즉 사용자가 직접 접근 가능한 쓰레드의 수 지정이 가능하다.

 

### CPU의 메모리 I/O 도중 생기는 병목 현상 해결 방법

- 이러한 문제를 해결하기 위해 메모리를 계층화하여 병목현상을 해결하고 있다.
- 자주 접근하는 데이터의 경우에는 캐시에 저장하여 접근 속도를 향상 시킴으로써 부하를 줄이고 있다.



### Memory Hierarchy

![img](https://t1.daumcdn.net/cfile/tistory/9971F2395AC634A40C)

- 하드디스크, 메모리, 캐시, 레지스터가 있다.
- 레지스터와 캐시는 CPU 내부에 존재한다.
- 프로세서와 메모리 사이의 속도 차이를 해결한다.



### 메모리 할당 알고리즘

- 다양한 프로그램들이 메모리에 적재와 종료를 반복하면서 메모리 공간은 규칙적이지 않은 빈 공간이 계속 발생

- 빈 공간중 프로세스를 어느 곳에 할당해 줄지 정하는 알고리즘

- 최초 적합 (First-fit)

  - 메모리를 처음부터 검사하며 가장 첫번째로 사용가능한 공간에 할당해준다.
  - 장점 - 빠른 메모리 할당 가능

  - 단점 - 공간 활용률이 떨어짐

- 최적 적합 (Best-fit)
  - 메모리 공간 중 프로세스가 들어갈 수 있는 가장 작은 공간에 할당해준다.
  - 장점 - 공간 활용률이 높아짐
  - 단점 - 사용 가능한 메모리가 크기 순으로 정렬되있지 않으면 메모리 검색 시간이 늘어난다.

- 최악 적합 (Worst-fit / Next-fit)
  - 프로세스를 메모리 공간 중 가장 큰 곳에 할당해준다.
  - 장점 - 큰 메모리에 바로 할당하므로 검색이 빠르다.
  - 단점 - 사용 가능한 메모리의 정렬이 필요하고 공간 활용률이 떨어질 수 있다. 



### Cache Memory

- 지역성을 이용해 CPU가 어떤 데이터를 원할 것인가를 어느 정도 에측해 캐시 메모리에 데이터를 저장
- 시간지역성(Temporal Locality)
  - 최근에 참조된 주소의 내용이 재참조될 가능성이 높은 특성 
- 공간지역성(Spatial Locality)
  - 최근에 참조된 주소의 인접한 데이터가 참조될 가능성이 높은 특성



### 가상메모리와 페이지폴트

![img](https://blog.kakaocdn.net/dn/ccf6O2/btqKL9ZmBi3/5bAhWIq2xYooTQ8JbQaPv0/img.png)

- 가상메모리는 RAM의 부족한 용량을 보완하기 위해, 각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 할당하는 방식
- OS는 프로세스들의 내용(페이지) 중에서 덜 중요한 것들을 하드디스크에 옮겨 놓고, 관련 정보를 페이지 테이블에 기록한다. 
- 페이지 테이블에는 Valid bit이 있어, 이를 이용해 해당 페이지가 어느 메모리에 있는지 표시할 수 있다.
- CPU는 프로세스를 실행하면서 페이지 테이블을 통해 페이지를 조회하는데, 실제메모리에 원하는 페이지가 없는 상황이 발생할 수 있다.(Valid bit를 통해 확인). 이것을 페이지 폴트라고 하는데 프로세스가 동작하면서 실제메모리에 필요한 데이터(페이지)가 없으면 가상메모리를 통해서 해당 데이터를 가져오게 된다. 
- 가상메모리는 하드디스크에 저장되어 있기 때문에, 페이지폴트가 발생하면 I/O에 의한 속도의 저하가 발생한다.



### 운영체제가 페이지 테이블을 이용하여, 요구 페이징을 수행하는 과정

1. CPU는 물리 메모리을 확인하여 페이지가 없으면 trap을 발생하여 운영체제에 알린다.

2. 운영체제는 CPU의 동작을 잠시 멈춘다.

3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단한다.

4. 페이지 폴트이면, 현재 물리 메모리에 비어있는 프레임(Free Frame)이 있는지 찾는다.
   - 비어있는 프레임이 없으면 페이지 교체 알고리즘에 의해서 교체한다.

5. 비어있는 프레임에 해당 페이지를 로드하고, 페이지 테이블을 최신화 한다.

6. 중단되었던 CPU를 다시 시작한다. 



### 페이지 교체 알고리즘과 LRU(Least Recently Used)

- LRU(Least Recently Used)는 페이지를 교체하기 위한 알고리즘 중 하나이다
- 페이지를 교체하는 이유는 가상메모리를 통해 조회한 페이지는 다시 사용될 가능성이 높기 때문이다. 페이지 교체를 위해서는 실제메모리에 존재하는 페이지를 가상메모리로 저장한 후에, 가상메모리에서 조회한 페이지를 실제 메모리로 로드해야 됩니다. 그렇다면 어떤 실제메모리의 페이지를 가상메모리로 희생시킬 것이냐에 대한 문제가 발생하는데, 이때 사용하는 알고리즘 중 하나가 LRU(Least Recently Used) 알고리즘 이다.
- LRU :  알고리즘은 실제메모리의 페이지들 중에서 가장 오랫동안 사용되지 않은 페이지를 선택하는 방식
- FIFO(First In First Out) 알고리즘 : 그 외에도 가장 먼저 물리 메모리에 적재된 페이지를 선택하는 방식인 
- LRU Approximation : LRU 알고리즘을 응용하여 페이지에 Second-Change를 준다.



### 단편화(외부 단편화 / 내부 단편화)

RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용 가능한 메모리가 충분히 존재하지만 할당이 불가능한 상태

- 내부 단편화 (Internal Fragmentation)

  - 메모리를 할당할 때 Process가 필요한 양보다 더 큰 메모리가 할당되어서 메모리 공간이 낭비되는 상황

- 외부 단편화(External Fragmentation)

  - 중간중간에 생긴 사용하지 않는 메모리가 많이 존재해서 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황

    

### Paging과 Segmentation의 차이점

- 페이징(paging)이 고정된 영역인 페이지(page)로 분할하였다면, 세그먼테이션은 가변적인 영역인 세그먼트(segment)로 분할함



### RISC와 CISC

프로세서가 가진 명령어 세트를 기준으로 RISC와 CISC로 나누니다.

- RISC (Reduce Instruction Set Computer)
  - 핵심적인 명령어를 기반으로 최소한의 명령어 세트를 구성한 프로세서다. 
  - 고정적인 길이와 간단한 명령어로 빠른 동작 속도를 자랑한다.
  - 적은 명령어 세트를 가지고 있으므로 프로그램을 구성하는 명령어가 단순하지만 다수의 명령어를 필요로 한다.
- CISC (Complex Instruction Set Computer)
  - 연산을 처리하는 복잡한 명령어들을 수백개 이상 탑재하고 있는 프로세서다. 
  - 명령어 길이가 다양하며 개수가 많아 프로그램의 구성이 복잡해지지만 소수의 명령어로 구현할 수 있다.



### 컴파일러와 인터프리터의 차이

- 컴파일러와 인터프리터 모두 고레벨 언어를 기계어로 변환하는 역할을 수행
- 차이점은 컴파일러의 경우 전체 코드를 보고 명령어를 수집하고 재구성하는 반면, 인터프리터는 소스코드의 각 행을 연속적으로 분석하며 실행
- 인터프리터는 고레벨 언어를 중간 레벨 언어로 한 번 변환하고 이를 각 행마다 실행하기 때문에 일반적으로 컴파일러가 인터프리터보다 실행 시간이 빠른 경우가 많다
- java의 경우 .java 파일을 .class 파일로 자바 컴파일러가 컴파일을 하고, .class 파일을 기계어로 인터프리터가 변환하는 것이다.



### 32비트 CPU와 64 비트 CPU

프로그램 실행을 요청받은 CPU가 한번에 처리할 수 있는 메모리의 크기이다. 즉, 32비트 CPU는 주어진 데이터를 32비트씩 잘라서 수행하고, 64비트 CPU는 64비트씩 잘라서 수행



### 프로그램 실행 순서

1. 사용자가 운영체제에게 프로그램 실행을 요청한다.
2. 운영체제는 프로그램의 정보를 HDD로 부터 읽어 할당된 메인 메모리 (code, data, stack, heap)에 적재한다.
3. CPU는 메인메모리에서 읽어온 정보를 바탕으로 차례로 코드를 실행한다.